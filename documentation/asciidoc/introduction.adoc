[[caps-introduction]]
= Introduction

[abstract]
--
This chapter introduces CAPS concepts and APIs, and gives examples for getting started with CAPS.
--

// TODO: Expand this to be a small but complete working example.
// TODO: Move code to somewhere testable.

When you start off with Cypher for Apache Spark, this is probably the very first thing you will do, unless you are importing a graph from Neo4j.
This section describes how to take CSV files, relations, or other tabular data and turn them into graphs which can be queried in CAPS.

To create a CAPS graph, follow these steps:

* Prepare your data in "tables for labels" format (described below).
* Map table columns to nodes/relationships. This interprets each row in that table as a node or as a relationship.
* Combine the tables with their node/relationship mappings into CAPS node/relationship tables.
* The nodes/relationships in these tables are interpreted as a graph by CAPS.

To understand this, we start with the "tables for labels" model.


[[graphs-from-tables-model]]
== Tables for labels

"Tables for labels" refers to a way of formatting tabular data such that the mapping to a graph is straightforward and easy.
To describe this briefly, it means that all nodes for the same combination of labels and all relationships with the same type are stored in their own table.
Each table for a label combination contains a primary key (which also acts as a node identifier) and each relationship table has its own identifier and two foreign keys that refer to the start/end nodes.


[[graphs-from-tables-example]]
=== Example

.Person
[[t.9bcf16bd9711e377ebe0a87d5c84ab79e1621b74]][[t.0]]
[width="100%",cols="50%,50%",]
|===
| id | name
| 1  | Mats
| 2  | Philip
|===

.Food
[[t.d88018b88b73b82f2f7568b87464f9e3791486c5]][[t.1]]
[width="100%",cols="50%,50%",]
|===
| id | name
| 3  | Apples
| 4  | Oranges
|===

.Likes
[[t.3d7be1f4a5d0664f30c42c1e327d86c1f5f60a2a]][[t.2]]
[width="100%",cols="34%,33%,33%",]
|===
| rel_id | person_id | food_id
| 5      | 1         | 3
| 6      | 2         | 4
|===

This is a graph in "tables for labels" format.

It corresponds to a graph that looks like this:

[source, cypher]
----
CREATE (:Person {name: 'Mats'})-[:LIKES]->(:Food {name: 'Apples'})
CREATE (:Person {name: 'Philip'})-[:LIKES]->(:Food {name: 'Oranges'});
----

Note that the `id` fields do not automatically become properties.
They are used to uniquely identify entities and to connect nodes with relationships.

With the SQL Property Graph DataSource, this mapping can be described using the Graph DDL language.
This means that CAPS can generate identifiers for nodes and relationships on the fly.


[[graphs-from-tables-constraints]]
=== Important CAPS constraints on "tables for labels"

* Every table must have a column with a unique ID.
* The unique ID must be a 64-bit integer (string IDs are presently not supported).
* The ID space of nodes can overlap with that of relationships, but within each space the ID must be unique.


[[graphs-from-tables-normalization]]
=== Normalize your data

Notice that in the example above, the data is highly normalized.
In the relational world it would be typical to have multiple entries for the same node in a denormalized table.
This would represent a "one-to-many" relationship, for example:

.Purchases
[[t.ca4a94ae2b1fa7f4d16b0db134a0d328b73ef808]][[t.3]]
[width="100%",cols="20%,20%,20%,20%,20%",]
|===
| customer_id | customer_name | product_id | product_name | quantity
| 1           | Bob           | 2          | Socks        | 2
| 1           | Bob           | 3          | Shirts       | 5
|===

This data is not in "tables for labels" format, rather we would probably model this in a graph as `(:Customer)-[:PURCHASED]\->(:Product)`.
In order to convert this data into the "tables for labels" format, we would have to refactor the data into three tables: Customer, Product, and PURCHASED.
Alternatively, we can express a mapping from this table using Graph DDL.


[[graphs-from-tables-multiple-labels]]
=== Multiply labeled nodes

In the "tables for labels" format, suppose we had a node that was a `:Person` and also an `:Employee`, while other nodes are labelled `:Person:Customer`.
In this kind of a setup, there would need to be two tables: Person_Employee (containing all nodes that were labeled with both of those) and a Person_Customer table.
The set of all persons is the union of both tables, and we can ensure that each person is only stored once.
This allows to define different properties for `:Customer` and `:Employee`.


[[graph-from-tables-definition]]
== Defining a graph

Given a set of tables, there are two ways to convert them to a graph:

* Manually with the <<graph-from-tables-scala-api, Scala API>>
* Using the SQL Property Graph Data Source (PGDS) with a <<graph-from-tables-graph-ddl, Graph DDL>>

If the data is already in the "tables for labels" format and contains unique identifiers, then using the Scala API is simpler.
If the data is denormalised and does not contain unique identifiers, then we recommend using the Graph DDL.


[[graph-from-tables-scala-api]]
=== Scala API


[[graphs-from-tables-data-preparation]]
==== Preparing your data

The recommended way to convert complex tables into graphs is to use the SQL PGDS with the Graph DDL.

Alternatively, tables can be imported with the Scala API.
We recommend using Spark SQL to import the tables and convert them into the suitable "tables for labels" format.
Please consult the Spark and Spark SQL documentation.

For the next step, we assume that you have DataFrames that are in the "tables for labels" format described above.


[[graphs-from-tables-graph-mappings]]
==== Express graph mappings

To manually define the graph mapping for tables we can use the Scala API.
Graph mappings allow CAPS to map rows in DataFrames to nodes or relationships.
These are the mappings for the person/food tables in the example above:

[source, scala]
----
val personMapping = NodeMapping
        .withSourceIdKey("id")
        .withImpliedLabel("Person")
        .withPropertyKeys("name")

val foodMapping = NodeMapping
        .withSourceIdKey("id")
        .withImpliedLabel("Food")
        .withPropertyKeys("name")

val likesMapping = RelationshipMapping
        .withSourceIdKey("rel_id")
        .withSourceStartNodeKey("person_id")
        .withSourceEndNodeKey("food_id")
        .withRelType("LIKES")
----

Here we create one mapping for each label and relationship type.
These mappings allow to interpret tables as a graph.


[[graphs-from-tables-entity-tables]]
==== Create CAPS tables, and then the graph

We combine the mappings with the tables in order to create node and relationship tables:

[source, scala]
----
val personNodes = CAPSNodeTable.fromMapping(personMapping, personDataFrame)
val foodNodes = CAPSNodeTable.fromMapping(foodMapping, foodDataFrame)
val likesRels = CAPSRelationshipTable.fromMapping(likesMapping, likesDataMapping)
val graph = capsSession.readFrom(personNodes, foodNodes, likesRels)
----

Now we have everything we need to run Cypher queries on our newly defined graph.

[[graphs-from-tables-id-types]]
=== Supported identifier types

CAPS uses Sparks' `BinaryType` to represent identifiers internally.
Identifiers uniquely identify nodes and relationships, as well as start and end nodes for relationships.
During the creation of a `CAPSNodeTable` or a `CAPSRelationshipTable`, we automatically convert the specified identifier columns to `BinaryType`.
At the moment, the conversion is supported for `LongType`, `IntegerType` and `StringType`.
If your identifier has a different data type, you need to convert it to one of the supported types before creating a CAPS table.

Using this mechanism, you can re-use identifiers that you might already have, e.g. in a CSV file or a relational table.
Note, that node identifiers must be unique within the set of all nodes and relationship identifiers must be unique within the set of all relationships.
If your identifiers are only unique within a CSV file or a table, one way to make them globally unique is to prepend the file or table name (i.e., the intended label) to the identifier.
However, this also requires updating start and end node identifiers for relationships.


[[graph-from-tables-graph-ddl]]
=== Graph DDL

The Graph DDL is a language to describe a mapping from a set of relational tables and views to a graph.

The tables are automatically imported from a relational database.
Currently CAPS supports JDBC and Hive tables.
Note that any Spark DataFrames can be registered as Hive table.
This means that the Graph DDL is always an alternative to the Scala API when mapping tables to a graph.

For the person/food tables above, the following Graph DDL could operate on a denormalized table, but assumes that a view for each label/relationship has been created:

[source, graphddl]
----
CATALOG CREATE LABEL (Person {name: STRING})
CATALOG CREATE LABEL (Food {name: STRING})
CATALOG CREATE LABEL [LIKES]

CREATE GRAPH SCHEMA peopleFood

  (Person)-[LIKES]->(Food)

CREATE GRAPH foodGraph USING SCHEMA peopleFood

  NODES (Person) FROM view_Persons

  NODES (Food) FROM view_Food

  RELATIONSHIP [LIKES]
    FROM view_Likes
      MAPPING (person_id) ONTO view_Persons(id)
      MAPPING (food_id) ONTO view_Food(id)
----

Note that unlike the Scala API, the SQL PGDS will take care of automatically generating identifiers for nodes and relationships.
The identifier generation strategy can be selected upon creation of a SQL PGDS.

For more details on Graph DDL, see the <<backend-graphddl, Graph DDL documentation>>.

[[graphs-from-tables-cypher-example]]
== Running Cypher

Once you have defined a CAPS graph, executing a Cypher query on it is straightforward:

[source, scala]
----
val result = graph.cypher("MATCH (p:Person)-[:LIKES]->(f:Food) RETURN p.name, f.name")
result.records.show
----

This executes the Cypher query and then prints the result table.
