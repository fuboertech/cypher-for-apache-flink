[[performance]]
= Performance

[abstract]
--
This chapter describes caching and other performance considerations.
--

An important performance consideration is what data is cached when running a Spark application.
Because Spark tables are typically recomputed every time there is an action, it is important to cache intermediate results, particularly if they are expensive to compute or frequently reused.
Many Spark clusters encourage users to put large data sets on external network accessible storage, such as S3, and in these cases caching becomes especially important to ensure that the data set is not repeatedly downloaded.
This article contains some general guidelines on how caching is used with Spark: https://unraveldata.com/to-cache-or-not-to-cache/[To Cache or Not to Cache].


[[caching-and-performance-table-caching]]
== Cache the backing table

CAPS graphs are generally backed by tables that contain nodes/relationships, which are in turn implemented by Spark tables.
The underlying Spark tables can be cached like this:

[source, scala]
----
val myTable = CAPSNodeTable(...)
myTable.table.cache()
----

Alternatively, you can call `.persist()` on the Spark table and specify a storage level as you usually would in Spark.


[[caching-and-performance-graph-caching]]
== Cache the graph

[source, scala]
----
import org.opencypher.spark.impl.CAPSConverters._

val graph = session.readFrom(stuff, things).asCaps
graph.cache()
----
